{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0ebec9-d1e0-4df6-aa03-259960ded73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58ff406-6bf3-4674-96f6-780904ed5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=None\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3617a9-b523-4bec-b4a4-0465eb9f3049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "data['Amount']=sc.fit_transform(pd.DataFrame(data['Amount']))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb5e341-dd1c-44ff-9457-87a322226f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(['Time'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389ff0a4-0d77-449e-bf18-9da2504fa7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fcec22-cb2f-4036-a34d-f0537f61e64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697bd9b1-1463-41e4-b9c1-74a6af2e0ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE:\n",
      " 0    199020\n",
      "1    199020\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('creditcard.csv')  # Update path if needed\n",
    "\n",
    "# ============================\n",
    "# ✅ Standardize 'Time' and 'Amount' Separately\n",
    "# ============================\n",
    "scaler_amount = StandardScaler()\n",
    "scaler_time = StandardScaler()\n",
    "\n",
    "# Fit and transform 'Amount' and 'Time' separately\n",
    "df['Amount'] = scaler_amount.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['Time'] = scaler_time.fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "# ============================\n",
    "# 📌 Separate Features and Target\n",
    "# ============================\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# ============================\n",
    "# 📌 Train-Test Split\n",
    "# ============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# ============================\n",
    "# ⚙️ Apply SMOTE to Training Data\n",
    "# ============================\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# ✅ Check Class Distribution After SMOTE\n",
    "print('Class distribution after SMOTE:\\n', pd.Series(y_train_res).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "951f5b8f-fd78-4d32-a8f3-6f9c1e158f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.7359 - val_loss: 0.5223\n",
      "Epoch 2/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.4949 - val_loss: 0.4623\n",
      "Epoch 3/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.4625 - val_loss: 0.4397\n",
      "Epoch 4/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.4618 - val_loss: 0.4261\n",
      "Epoch 5/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.4138 - val_loss: 0.4185\n",
      "Epoch 6/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.4010 - val_loss: 0.3989\n",
      "Epoch 7/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.4082 - val_loss: 0.3914\n",
      "Epoch 8/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.3835 - val_loss: 0.3829\n",
      "Epoch 9/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.3808 - val_loss: 0.3743\n",
      "Epoch 10/10\n",
      "\u001b[1m2488/2488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.3662 - val_loss: 0.3685\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12439/12439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step\n",
      "Autoencoder Performance:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     85295\n",
      "           1       0.03      0.84      0.05       148\n",
      "\n",
      "    accuracy                           0.95     85443\n",
      "   macro avg       0.51      0.89      0.51     85443\n",
      "weighted avg       1.00      0.95      0.97     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ============================\n",
    "# 📦 Build Autoencoder\n",
    "# ============================\n",
    "input_dim = X_train_res.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Encoder\n",
    "encoder = Dense(14, activation=\"tanh\")(input_layer)\n",
    "encoder = Dense(7, activation=\"relu\")(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Dense(14, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='linear')(decoder)\n",
    "\n",
    "# Model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# ============================\n",
    "# 🏋️ Train Autoencoder on Non-Fraud Data\n",
    "# ============================\n",
    "X_train_ae = X_train_res[y_train_res == 0]  # Use only class 0 for training\n",
    "\n",
    "history = autoencoder.fit(X_train_ae, X_train_ae,\n",
    "                          epochs=10,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          validation_split=0.2,\n",
    "                          verbose=1)\n",
    "\n",
    "# ============================\n",
    "# 🧮 Calculate Reconstruction Error on Test Set\n",
    "# ============================\n",
    "X_test_predictions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - X_test_predictions, 2), axis=1)\n",
    "\n",
    "# Set Threshold (95th Percentile on Normal Transactions)\n",
    "threshold = np.percentile(mse[y_test == 0], 95)\n",
    "\n",
    "# Save the threshold for manual testing\n",
    "joblib.dump(threshold, 'best_threshold.pkl')\n",
    "\n",
    "# Save the trained autoencoder model\n",
    "autoencoder.save('autoencoder_model.h5')\n",
    "\n",
    "# ============================\n",
    "# 🔍 Autoencoder Predictions\n",
    "# ============================\n",
    "y_pred_ae = [1 if e > threshold else 0 for e in mse]\n",
    "\n",
    "# Calculate mse_min and mse_max for normalization (on training non-fraud samples)\n",
    "ae_train_predictions = autoencoder.predict(X_train_res)\n",
    "mse_train = np.mean(np.power(X_train_res - ae_train_predictions, 2), axis=1)\n",
    "\n",
    "mse_min = mse_train.min()\n",
    "mse_max = mse_train.max()\n",
    "\n",
    "# Save mse_min and mse_max for manual prediction\n",
    "joblib.dump(mse_min, 'mse_min.pkl')\n",
    "joblib.dump(mse_max, 'mse_max.pkl')\n",
    "\n",
    "# Normalize reconstruction error for ensemble use\n",
    "probs_ae = (mse - mse_min) / (mse_max - mse_min)\n",
    "\n",
    "# ============================\n",
    "# 📊 Performance Report\n",
    "# ============================\n",
    "print(\"Autoencoder Performance:\\n\")\n",
    "print(classification_report(y_test, y_pred_ae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d190fa-9220-48e6-9fa2-938c4154509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - accuracy: 0.9699 - loss: 0.0840 - val_accuracy: 0.9993 - val_loss: 0.0077\n",
      "Epoch 2/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0239 - val_accuracy: 0.9991 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 7.4110e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 6.1783e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 5.0301e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9998 - val_loss: 6.3902e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 4.7912e-04\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "CNN Performance:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.33      0.84      0.48       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.67      0.92      0.74     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Reshape input for CNN: (samples, features, 1)\n",
    "X_train_cnn = np.expand_dims(X_train_res, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# Build CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN\n",
    "cnn_model.fit(X_train_cnn, y_train_res, epochs=10, batch_size=64, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Predict probabilities\n",
    "probs_cnn = cnn_model.predict(X_test_cnn).flatten()\n",
    "y_pred_cnn = [1 if p >= 0.5 else 0 for p in probs_cnn]\n",
    "\n",
    "# Evaluation\n",
    "print(\"CNN Performance:\\n\")\n",
    "print(classification_report(y_test, y_pred_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7df427d-f142-47e8-a93f-99061a6132d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.70010667123488\n",
      "\n",
      "Ensemble Model Performance:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.89      0.78      0.83       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.89      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "ROC-AUC Score: 0.9561088464042915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "\n",
    "# Weighted Ensemble\n",
    "final_probs = (0.3 * probs_ae) + (0.7 * probs_cnn)\n",
    "\n",
    "# Find Optimal Threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, final_probs)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "\n",
    "# Final Predictions using Best Threshold\n",
    "y_pred_ensemble = [1 if p >= best_threshold else 0 for p in final_probs]\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"\\nEnsemble Model Performance:\\n\")\n",
    "print(classification_report(y_test, y_pred_ensemble))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, final_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a88dee-2341-41d3-8955-eda0e1cdabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      "🔍 Fraud Probability: 0.0002\n",
      "🧐 Predicted Class: Non-Fraud\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 🚨 Example New Transaction (replace with your transaction)\n",
    "# Full Transaction Input (includes Time)\n",
    "new_transaction = np.array([[\n",
    "472.0, -3.0435406239976, -3.15730712090228, 1.08846277997285, 2.2886436183814,\n",
    "1.35980512966107, -1.06482252298131, 0.325574266158614, -0.0677936531906277, -0.270952836226548, -0.838586564582682, -0.414575448285725, -0.503140859566824, 0.676501544635863, -1.69202893305906, 2.00063483909015, 0.666779695901966, 0.599717413841732, 1.72532100745514, 0.283344830149495, 2.10233879259444, 0.661695924845707, 0.435477208966341, 1.37596574254306, -0.293803152734021, 0.279798031841214, -0.145361714815161, -0.252773122530705, 0.0357642251788156, 529.0]])\n",
    "# ============================\n",
    "# 📌 Step 1: Scale 'Time' and 'Amount'\n",
    "# ============================\n",
    "new_transaction[:, 0] = scaler_time.transform(new_transaction[:, 0].reshape(-1, 1)).flatten()\n",
    "new_transaction[:, 29] = scaler_amount.transform(new_transaction[:, 29].reshape(-1, 1)).flatten()\n",
    "\n",
    "# ============================\n",
    "# 📌 Step 2: Autoencoder Prediction\n",
    "# ============================\n",
    "ae_prediction = autoencoder.predict(new_transaction)\n",
    "mse_new = np.mean(np.power(new_transaction - ae_prediction, 2), axis=1)\n",
    "prob_ae_new = (mse_new - mse_min) / (mse_max - mse_min)\n",
    "\n",
    "# ============================\n",
    "# 📌 Step 3: CNN Prediction\n",
    "# ============================\n",
    "new_transaction_cnn = np.expand_dims(new_transaction, axis=2)\n",
    "prob_cnn_new = cnn_model.predict(new_transaction_cnn).flatten()\n",
    "\n",
    "# ============================\n",
    "# 📌 Step 4: Ensemble Probability\n",
    "# ============================\n",
    "final_prob_new = (0.3 * prob_ae_new) + (0.7 * prob_cnn_new)\n",
    "\n",
    "# ============================\n",
    "# 📌 Step 5: Final Prediction\n",
    "# ============================\n",
    "predicted_class = 1 if final_prob_new >= best_threshold else 0\n",
    "\n",
    "# ============================\n",
    "# 📌 Step 6: Output\n",
    "# ============================\n",
    "print(f\"\\n🔍 Fraud Probability: {final_prob_new[0]:.4f}\")\n",
    "print(f\"🧐 Predicted Class: {'Fraud' if predicted_class == 1 else 'Non-Fraud'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a0c51b-250f-4a93-8f11-cce730bab2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction 1: [406.0, -2.3122265423263, 1.95199201064158, -1.60985073229769, 3.9979055875468, -0.522187864667764, -1.42654531920595, -2.53738730624579, 1.39165724829804, -2.77008927719433, -2.77227214465915, 3.20203320709635, -2.89990738849473, -0.595221881324605, -4.28925378244217, 0.389724120274487, -1.14074717980657, -2.83005567450437, -0.0168224681808257, 0.416955705037907, 0.126910559061474, 0.517232370861764, -0.0350493686052974, -0.465211076182388, 0.320198198514526, 0.0445191674731724, 0.177839798284401, 0.261145002567677, -0.143275874698919, 0.0]\n",
      "\n",
      "Fraud Transaction 2: [472.0, -3.0435406239976, -3.15730712090228, 1.08846277997285, 2.2886436183814, 1.35980512966107, -1.06482252298131, 0.325574266158614, -0.0677936531906277, -0.270952836226548, -0.838586564582682, -0.414575448285725, -0.503140859566824, 0.676501544635863, -1.69202893305906, 2.00063483909015, 0.666779695901966, 0.599717413841732, 1.72532100745514, 0.283344830149495, 2.10233879259444, 0.661695924845707, 0.435477208966341, 1.37596574254306, -0.293803152734021, 0.279798031841214, -0.145361714815161, -0.252773122530705, 0.0357642251788156, 529.0]\n",
      "\n",
      "Fraud Transaction 3: [4462.0, -2.30334956758553, 1.759247460267, -0.359744743330052, 2.33024305053917, -0.821628328375422, -0.0757875706194599, 0.562319782266954, -0.399146578487216, -0.238253367661746, -1.52541162656194, 2.03291215755072, -6.56012429505962, 0.0229373234890961, -1.47010153611197, -0.698826068579047, -2.28219382856251, -4.78183085597533, -2.61566494476124, -1.33444106667307, -0.430021867171611, -0.294166317554753, -0.932391057274991, 0.172726295799422, -0.0873295379700724, -0.156114264651172, -0.542627889040196, 0.0395659889264757, -0.153028796529788, 239.93]\n",
      "\n",
      "Fraud Transaction 4: [6986.0, -4.39797444171999, 1.35836702839758, -2.5928442182573, 2.67978696694832, -1.12813094208956, -1.70653638774951, -3.49619729302467, -0.248777743025673, -0.24776789948008, -4.80163740602813, 4.89584422347523, -10.9128193194019, 0.184371685834387, -6.77109672468083, -0.0073261825777121, -7.35808322132346, -12.5984185405511, -5.13154862842983, 0.308333945758691, -0.17160787864796, 0.573574068424352, 0.176967718048195, -0.436206883597401, -0.0535018648884285, 0.252405261951833, -0.657487754764504, -0.827135714578603, 0.849573379985768, 59.0]\n",
      "\n",
      "Fraud Transaction 5: [7519.0, 1.23423504613468, 3.0197404207034, -4.30459688479665, 4.73279513041887, 3.62420083055386, -1.35774566315358, 1.71344498787235, -0.496358487073991, -1.28285782036322, -2.44746925511151, 2.10134386504854, -4.6096283906446, 1.46437762476188, -6.07933719308005, -0.339237372732577, 2.58185095378146, 6.73938438478335, 3.04249317830411, -2.72185312222835, 0.0090608363953452, -0.37906830709218, -0.704181032215427, -0.656804756348389, -1.63265295692929, 1.48890144838237, 0.566797273468934, -0.0100162234965625, 0.146792734916988, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Extract fraud transactions\n",
    "fraud_transactions = df[df['Class'] == 1]\n",
    "\n",
    "# Select the first N fraud transactions (for example, N=5)\n",
    "N = 5\n",
    "fraud_features_list = fraud_transactions.drop('Class', axis=1).head(N).values.tolist()\n",
    "\n",
    "# Display the fraud transactions\n",
    "for idx, transaction in enumerate(fraud_features_list, 1):\n",
    "    print(f\"Fraud Transaction {idx}: {transaction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5653ad14-a93e-437f-836a-82a3f022c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Fraud Transaction 1: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "\n",
      "Non-Fraud Transaction 2: [0.0, 1.19185711131486, 0.26615071205963, 0.16648011335321, 0.448154078460911, 0.0600176492822243, -0.0823608088155687, -0.0788029833323113, 0.0851016549148104, -0.255425128109186, -0.166974414004614, 1.61272666105479, 1.06523531137287, 0.48909501589608, -0.143772296441519, 0.635558093258208, 0.463917041022171, -0.114804663102346, -0.183361270123994, -0.145783041325259, -0.0690831352230203, -0.225775248033138, -0.638671952771851, 0.101288021253234, -0.339846475529127, 0.167170404418143, 0.125894532368176, -0.0089830991432281, 0.0147241691924927, 2.69]\n",
      "\n",
      "Non-Fraud Transaction 3: [1.0, -1.35835406159823, -1.34016307473609, 1.77320934263119, 0.379779593034328, -0.503198133318193, 1.80049938079263, 0.791460956450422, 0.247675786588991, -1.51465432260583, 0.207642865216696, 0.624501459424895, 0.066083685268831, 0.717292731410831, -0.165945922763554, 2.34586494901581, -2.89008319444231, 1.10996937869599, -0.121359313195888, -2.26185709530414, 0.524979725224404, 0.247998153469754, 0.771679401917229, 0.909412262347719, -0.689280956490685, -0.327641833735251, -0.139096571514147, -0.0553527940384261, -0.0597518405929204, 378.66]\n",
      "\n",
      "Non-Fraud Transaction 4: [1.0, -0.966271711572087, -0.185226008082898, 1.79299333957872, -0.863291275036453, -0.0103088796030823, 1.24720316752486, 0.23760893977178, 0.377435874652262, -1.38702406270197, -0.0549519224713749, -0.226487263835401, 0.178228225877303, 0.507756869957169, -0.28792374549456, -0.631418117709045, -1.0596472454325, -0.684092786345479, 1.96577500349538, -1.2326219700892, -0.208037781160366, -0.108300452035545, 0.0052735967825345, -0.190320518742841, -1.17557533186321, 0.647376034602038, -0.221928844458407, 0.0627228487293033, 0.0614576285006353, 123.5]\n",
      "\n",
      "Non-Fraud Transaction 5: [2.0, -1.15823309349523, 0.877736754848451, 1.548717846511, 0.403033933955121, -0.407193377311653, 0.0959214624684256, 0.592940745385545, -0.270532677192282, 0.817739308235294, 0.753074431976354, -0.822842877946363, 0.53819555014995, 1.3458515932154, -1.11966983471731, 0.175121130008994, -0.451449182813529, -0.237033239362776, -0.0381947870352842, 0.803486924960175, 0.408542360392758, -0.0094306971323291, 0.79827849458971, -0.137458079619063, 0.141266983824769, -0.206009587619756, 0.502292224181569, 0.219422229513348, 0.215153147499206, 69.99]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Extract non-fraud transactions (Class == 0)\n",
    "non_fraud_transactions = df[df['Class'] == 0]\n",
    "\n",
    "# Select the first N non-fraud transactions (for example, N=5)\n",
    "N = 5\n",
    "non_fraud_features_list = non_fraud_transactions.drop('Class', axis=1).head(N).values.tolist()\n",
    "\n",
    "# Display the non-fraud transactions\n",
    "for idx, transaction in enumerate(non_fraud_features_list, 1):\n",
    "    print(f\"Non-Fraud Transaction {idx}: {transaction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85031af0-7c44-4be6-8de1-51273823e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "⚠️ FRAUD DETECTED (Anomalous Transaction)\n",
      "\n",
      "Reconstruction MSE: 31.44596290588379\n",
      "Normalized Score: 0.02183462493121624\n",
      "Threshold: 0.7501180421304944\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model and saved values\n",
    "autoencoder = load_model('autoencoder_model.h5')\n",
    "threshold = joblib.load('best_threshold.pkl')\n",
    "mse_min = joblib.load('mse_min.pkl')\n",
    "mse_max = joblib.load('mse_max.pkl')\n",
    "\n",
    "# Input sample (30 features now — added 0.0 at the end)\n",
    "sample = np.array([[\n",
    "    -5.60369027985602, 5.22219270751471, -7.51682997724608, 8.11772427554261, -2.75685795265464,\n",
    "    -1.57456462233583, -6.33034325040366, 2.99841888080239, -4.50816689310713, -7.33437708370839,\n",
    "    7.18872396524447, -10.6551809118898, 2.59467986078199, -10.242859083204, -0.191158119172494,\n",
    "    -5.50433407013933, -8.69777741257031, -1.93422536185434, 1.95874993153475, 0.227525994742654,\n",
    "    1.24289620552409, 0.428408392466797, -0.101183595116722, -0.520199121186447, -0.176937756589733,\n",
    "    0.461449982566097, -0.106625180749266, -0.479661947808134, -0.3532293929668235, 0.0  # Added dummy value\n",
    "]], dtype=np.float32)\n",
    "\n",
    "# Predict and calculate reconstruction error\n",
    "reconstructed = autoencoder.predict(sample)\n",
    "mse = np.mean(np.power(sample - reconstructed, 2), axis=1)\n",
    "normalized_score = (mse - mse_min) / (mse_max - mse_min)\n",
    "\n",
    "# Decision\n",
    "if mse > threshold:\n",
    "    print(\"⚠️ FRAUD DETECTED (Anomalous Transaction)\")\n",
    "else:\n",
    "    print(\"✅ CLEAN TRANSACTION\")\n",
    "\n",
    "# Show details\n",
    "print(f\"\\nReconstruction MSE: {mse[0]}\")\n",
    "print(f\"Normalized Score: {normalized_score[0]}\")\n",
    "print(f\"Threshold: {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1dcb87-5fa7-48f3-aec6-3b07eaccc1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "⚠️ FRAUD DETECTED (Anomalous Transaction)\n",
      "\n",
      "🔍 Reconstruction MSE: 4473.942865170267\n",
      "📈 Normalized Score   : 3.108712714820376\n",
      "📊 Threshold (cutoff) : 0.7501180421304944\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "# === Step 1: Load trained autoencoder and thresholds ===\n",
    "autoencoder = load_model('autoencoder_model.h5')\n",
    "threshold = joblib.load('best_threshold.pkl')     # Threshold to decide fraud\n",
    "mse_min = joblib.load('mse_min.pkl')              # Minimum MSE during training\n",
    "mse_max = joblib.load('mse_max.pkl')              # Maximum MSE during training\n",
    "\n",
    "# === Step 2: Input sample (non-scaled, shape must be [1, 30]) ===\n",
    "sample = np.array([[1.0, -1.35835406159823, -1.34016307473609, 1.77320934263119, 0.379779593034328,\n",
    "                    -0.503198133318193, 1.80049938079263, 0.791460956450422, 0.247675786588991,\n",
    "                    -1.51465432260583, 0.207642865216696, 0.624501459424895, 0.066083685268831,\n",
    "                    0.717292731410831, -0.165945922763554, 2.34586494901581, -2.89008319444231,\n",
    "                    1.10996937869599, -0.121359313195888, -2.26185709530414, 0.524979725224404,\n",
    "                    0.247998153469754, 0.771679401917229, 0.909412262347719, -0.689280956490685,\n",
    "                    -0.327641833735251, -0.139096571514147, -0.0553527940384261, -0.0597518405929204,\n",
    "                    378.66]])\n",
    "\n",
    "# === Step 3: Predict and compute reconstruction error (MSE) ===\n",
    "reconstructed = autoencoder.predict(sample)\n",
    "mse = np.mean(np.square(sample - reconstructed), axis=1)\n",
    "\n",
    "# === Step 4: Normalize MSE (optional, for inspection) ===\n",
    "normalized_score = (mse - mse_min) / (mse_max - mse_min)\n",
    "\n",
    "# === Step 5: Detect fraud ===\n",
    "if mse[0] > threshold:\n",
    "    print(\"⚠️ FRAUD DETECTED (Anomalous Transaction)\")\n",
    "else:\n",
    "    print(\"✅ CLEAN TRANSACTION\")\n",
    "\n",
    "# === Step 6: Output details ===\n",
    "print(f\"\\n🔍 Reconstruction MSE: {mse[0]}\")\n",
    "print(f\"📈 Normalized Score   : {normalized_score[0]}\")\n",
    "print(f\"📊 Threshold (cutoff) : {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69e1f7bd-fe2a-412c-b0e2-d2d9a71088c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0326 - val_loss: 0.0014\n",
      "Epoch 2/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 3/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 9.4692e-04 - val_loss: 8.6708e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 8.6927e-04 - val_loss: 8.5796e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 8.4687e-04 - val_loss: 7.2808e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.3220e-04 - val_loss: 7.2313e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2620e-04 - val_loss: 7.2129e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2741e-04 - val_loss: 7.2369e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 7.2491e-04 - val_loss: 7.2066e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2364e-04 - val_loss: 7.2205e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.1897e-04 - val_loss: 7.2109e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2467e-04 - val_loss: 7.1728e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2500e-04 - val_loss: 7.2014e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2629e-04 - val_loss: 7.2043e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2426e-04 - val_loss: 7.1735e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 7.2149e-04 - val_loss: 7.2119e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2146e-04 - val_loss: 7.1715e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2303e-04 - val_loss: 7.1623e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.2248e-04 - val_loss: 7.1408e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_threshold.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# Drop 'Time' column and separate features and labels\n",
    "data = data.drop(columns=[\"Time\"])\n",
    "X = data.drop(columns=[\"Class\"])\n",
    "y = data[\"Class\"]\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Use only non-fraud transactions (Class == 0) for training\n",
    "X_train = X_scaled[y == 0]\n",
    "\n",
    "# Split into train and validation\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Autoencoder architecture\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(14, activation=\"tanh\")(input_layer)\n",
    "encoder = Dense(7, activation=\"relu\")(encoder)\n",
    "decoder = Dense(14, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='linear')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train, X_train, epochs=20, batch_size=64, shuffle=True, validation_data=(X_val, X_val))\n",
    "\n",
    "# Save the model\n",
    "autoencoder.save(\"autoencoder_model.h5\")\n",
    "\n",
    "# Compute reconstruction error on validation set\n",
    "reconstructions = autoencoder.predict(X_val)\n",
    "mse = np.mean(np.power(X_val - reconstructions, 2), axis=1)\n",
    "\n",
    "# Normalize reconstruction error for later prediction\n",
    "mse_min, mse_max = mse.min(), mse.max()\n",
    "joblib.dump(mse_min, \"mse_min.pkl\")\n",
    "joblib.dump(mse_max, \"mse_max.pkl\")\n",
    "\n",
    "# Choose best threshold (you can tune this further)\n",
    "threshold = np.percentile(mse, 95)  # 95th percentile\n",
    "joblib.dump(threshold, \"best_threshold.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f19877-dcb6-4a54-b8aa-0ae88ea8b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\ankit\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972ms/step\n",
      "✅ CLEAN TRANSACTION\n",
      "\n",
      "🔍 Reconstruction MSE: 0.0010168931065238033\n",
      "📈 Normalized Score   : 0.005517317096787096\n",
      "📊 Threshold (cutoff) : 0.0016657041300721935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load saved models and parametersfrom keras.losses import MeanSquaredError\n",
    "from keras.losses import MeanSquaredError\n",
    "autoencoder = load_model('autoencoder_model.h5', custom_objects={'mse': MeanSquaredError()})\n",
    "threshold = joblib.load('best_threshold.pkl')\n",
    "mse_min = joblib.load('mse_min.pkl')\n",
    "mse_max = joblib.load('mse_max.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Input a real non-fraud transaction (30 features)\n",
    "sample = np.array([[1.0, -1.35835406159823, -1.34016307473609, 1.77320934263119,\n",
    "                    0.379779593034328, -0.503198133318193, 1.80049938079263, 0.791460956450422,\n",
    "                    0.247675786588991, -1.51465432260583, 0.207642865216696, 0.624501459424895,\n",
    "                    0.066083685268831, 0.717292731410831, -0.165945922763554, 2.34586494901581,\n",
    "                    -2.89008319444231, 1.10996937869599, -0.121359313195888, -2.26185709530414,\n",
    "                    0.524979725224404, 0.247998153469754, 0.771679401917229, 0.909412262347719,\n",
    "                    -0.689280956490685, -0.327641833735251, -0.139096571514147, -0.0553527940384261,\n",
    "                    -0.0597518405929204]])\n",
    "\n",
    "# Scale the input\n",
    "sample_scaled = scaler.transform(sample)\n",
    "\n",
    "# Predict and calculate reconstruction error\n",
    "reconstructed = autoencoder.predict(sample_scaled)\n",
    "mse = np.mean(np.power(sample_scaled - reconstructed, 2), axis=1)\n",
    "normalized_score = (mse - mse_min) / (mse_max - mse_min)\n",
    "\n",
    "# Decision\n",
    "if mse[0] > threshold:\n",
    "    print(\"⚠️ FRAUD DETECTED (Anomalous Transaction)\")\n",
    "else:\n",
    "    print(\"✅ CLEAN TRANSACTION\")\n",
    "\n",
    "# Show details\n",
    "print(f\"\\n🔍 Reconstruction MSE: {mse[0]}\")\n",
    "print(f\"📈 Normalized Score   : {normalized_score[0]}\")\n",
    "print(f\"📊 Threshold (cutoff) : {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b92d5-492f-4ba6-a992-1b9f2b7c6ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
